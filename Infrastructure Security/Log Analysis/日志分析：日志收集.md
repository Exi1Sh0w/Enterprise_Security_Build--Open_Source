## 概述

## Beats
### Beats概述

### Beats安装
[安装文档](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html)

```
rpm -ivh filebeat-6.4.3-x86_64.rpm
```

### Beats配置
vim /etc/filebeat/filebeat.yml

[Input 配置](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-filebeat-options.html)

[Output 配置](https://www.elastic.co/guide/en/beats/filebeat/current/configuring-output.html)

### Beats案例

## Flume
### Flume概述
![flume-1](https://github.com/bloodzer0/Enterprise_Security_Build--Open_Source/blob/master/Infrastructure%20Security/Log%20Analysis/img/flume-1.png)

* Source：收集

* Channel：聚集

* Sink：输出

### Flume安装
```
# 解决依赖
tar -xf jdk-8u191-linux-x64.tar.gz -C /app/
vim /etc/profile
	export JAVA_HOME=/app/jdk1.8.0_191
	export PATH=$JAVA_HOME/bin:$PATH

source /etc/profile

# 验证java是否安装成功
java -version

# 下载flume，解压到指定目录
tar -xf apache-flume-1.8.0-bin.tar.gz -C /app/

# 配置环境变量
vim /etc/profile
	export FLUME_HOME=/app/apache-flume-1.8.0-bin
	export PATH=$FLUME_HOME/bin:$PATH

source /etc/profile

# 配置flume运行环境文件
cp /app/apache-flume-1.8.0-bin/conf/flume-env.sh.template /app/apache-flume-1.8.0-bin/conf/flume-env.sh
vim /app/apache-flume-1.8.0-bin/conf/flume-env.sh
	export JAVA_HOME=JAVA_PATH

# 查看是否安装完成
flume-ng version
```

![flume-2](https://github.com/bloodzer0/Enterprise_Security_Build--Open_Source/blob/master/Infrastructure%20Security/Log%20Analysis/img/flume-2.png)

### Flume案例
* **从指定网络端口采集数据输出到控制台：[官方文档](http://flume.apache.org/FlumeUserGuide.html#a-simple-example)**

/app/apache-flume-1.8.0-bin/conf/example-1.conf

```
# a1:agent名称
# r1:source名称
# c1:channel名称
# k1:sink名称

# Name the components on this agent
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

执行命令：

```
flume-ng agent --name a1 --conf /app/apache-flume-1.8.0-bin/conf --conf-file /app/apache-flume-1.8.0-bin/conf/example-1.conf -Dflume.root.logger=INFO,console

# 备注：-Dflume.root.logger=INFO,console（java参数，INFO输出到控制台）
```

![flume-3](https://github.com/bloodzer0/Enterprise_Security_Build--Open_Source/blob/master/Infrastructure%20Security/Log%20Analysis/img/flume-3.png)

对输出结果的说明：

```
Event是Flume数据传输的基本单元，Event=[header(可选)] + <body(必选)>
```

* **实时监控文件新增数据输出到控制台**

vim /app/apache-flume-1.8.0-bin/conf/example-2.conf

```
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /var/log/messages
a1.sources.r1.shell = /bin/sh -c

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

执行命令：

```
flume-ng agent --name a1 --conf /app/apache-flume-1.8.0-bin/conf --conf-file /app/apache-flume-1.8.0-bin/conf/example-2.conf -Dflume.root.logger=INFO,console
```

![flume-4](https://github.com/bloodzer0/Enterprise_Security_Build--Open_Source/blob/master/Infrastructure%20Security/Log%20Analysis/img/flume-4.png)

* **将Server1的日志传输到Server2的控制台**

vim /app/apache-flume-1.8.0-bin/conf/exec-memory-avro.conf

```
exec-memory-avro.sources = exec-source
exec-memory-avro.sinks = avro-sink
exec-memory-avro.channels = memory-channel

exec-memory-avro.sources.exec-source.type = exec
exec-memory-avro.sources.exec-source.command = tail -F /var/log/messages
exec-memory-avro.sources.exec-source.shell = /bin/sh -c

exec-memory-avro.sinks.avro-sink.type = avro
exec-memory-avro.sinks.avro-sink.hostname = localhost
exec-memory-avro.sinks.avro-sink.port = 44444

exec-memory-avro.channels.memory-channel.type = memory
exec-memory-avro.channels.memory-channel.capacity = 1000
exec-memory-avro.channels.memory-channel.transactionCapacity = 100

exec-memory-avro.sources.exec-source.channels = memory-channel
exec-memory-avro.sinks.avro-sink.channel = memory-channel
```

vim /app/apache-flume-1.8.0-bin/conf/avro-memory-logger.conf

```
avro-memory-logger.sources = avro-source
avro-memory-logger.sinks = logger-sink
avro-memory-logger.channels = memory-channel

avro-memory-logger.sources.avro-source.type = avro
avro-memory-logger.sources.avro-source.bind = localhost
avro-memory-logger.sources.avro-source.port = 44444

avro-memory-logger.sinks.logger-sink.type = logger

avro-memory-logger.channels.memory-channel.type = memory
avro-memory-logger.channels.memory-channel.capacity = 1000
avro-memory-logger.channels.memory-channel.transactionCapacity = 100

avro-memory-logger.sources.avro-source.channels = memory-channel
avro-memory-logger.sinks.logger-sink.channel = memory-channel
```

执行命令：**备注：需要先启动接收端也就是需要先启动Server2**

```
flume-ng agent --name avro-memory-logger --conf /app/apache-flume-1.8.0-bin/conf --conf-file /app/apache-flume-1.8.0-bin/conf/avro-memory-logger.conf -Dflume.root.logger=INFO,console

flume-ng agent --name exec-memory-avro --conf /app/apache-flume-1.8.0-bin/conf --conf-file /app/apache-flume-1.8.0-bin/conf/exec-memory-avro.conf -Dflume.root.logger=INFO,console
```

## rsyslog
### rsyslog安装
备注：Centos7默认安装有rsyslog，需要额外安装往kafka传输消息的模块：

```
wget http://rpms.adiscon.com/v8-stable/rsyslog.repo -O /etc/yum.repos.d/rsyslog.repo

yum install rsyslog-kafka.x86_64 -y
```

### rsyslog配置
* rsyslog与Kafka配置：[官方文档](https://www.rsyslog.com/connecting-with-logstash-via-apache-kafka/)

### rsyslog案例


[参考点我](https://github.com/bloodzer0/Enterprise_Security_Build--Open_Source/tree/master/Infrastructure%20Security/Log%20Analysis)

* **rsyslog转发到rsyslog server**
* **rsyslog转发到kafka cluster**

## Logstash
### Logstash安装
[官方文档](https://www.elastic.co/guide/en/logstash/current/installing-logstash.html)

### Logstash案例
